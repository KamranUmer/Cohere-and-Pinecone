{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamranUmer/Cohere-and-Pinecone/blob/main/Cohere_AI's_LLM_for_Semantic_Search_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnbNRZTDNA1M"
      },
      "source": [
        "# Semantic Search with Cohere and Pinecone\n",
        "\n",
        "In this notebook we will demonstrate how to perform semantic search for identifying similar or duplicate questions using Cohere and Pinecone.\n",
        "\n",
        "![Steps in semantic search process](https://raw.githubusercontent.com/pinecone-io/examples/master/integrations/cohere/assets/index_query_pinecone_cohere.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0974WnM7NA1O"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUqE_6bcNA1O"
      },
      "source": [
        "We first need to setup our environment and retrieve API keys for Cohere and Pinecone. Let's start with our environment, we need HuggingFace *Datasets* for our data, and the Cohere and Pinecone clients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhmhz2D3NA1P",
        "outputId": "ed931460-7a47-403c-d795-4149bd100b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.37-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m756.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Installing collected packages: pyarrow-hotfix, loguru, fastavro, dnspython, dill, backoff, pinecone-client, multiprocess, cohere, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.37 datasets-2.15.0 dill-0.3.7 dnspython-2.4.2 fastavro-1.9.1 loguru-0.7.2 multiprocess-0.70.15 pinecone-client-2.2.4 pyarrow-hotfix-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install cohere pinecone-client datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aPF7S50NA1P"
      },
      "source": [
        "And sign up for an API key over at [Cohere](https://os.cohere.ai/) and [Pinecone](https://app.pinecone.io), you can enter the keys directly in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAVUltZjhJ4I",
        "outputId": "e55e33d7-424e-41d1-ab6d-30c688d24b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ =  load_dotenv(dotenv_path=\"/content/drive/MyDrive/Cohere AI's LLM for Semantic Search in Python/.env\")\n",
        "# apit =\n",
        "COHERE_KEY  = os.environ['COHERE_KEY']\n",
        "PINECONE_KEY  = os.environ['PINECONE_KEY']\n",
        "environment = os.environ['environment']\n",
        "\n"
      ],
      "metadata": {
        "id": "RQB2XlgqhSHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95KrmFq6NA1Q"
      },
      "source": [
        "## Create Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yQxt8ukNA1R"
      },
      "source": [
        "We can create sentence embeddings easily using Cohere. First, we import the Cohere client and initialize our connection using the API key we retrieved earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPllmdUWNA1R"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.Client(COHERE_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXRk3gMENA1R"
      },
      "source": [
        "We will load the **T**ext **RE**trieval **C**onference (TREC) question classification dataset which contains 5.5K labeled questions. We will take the first 1K samples for this demo, but this can be scaled to millions or even billions of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qOsNCLNA1S",
        "outputId": "e923442b-1b36-4615-c28a-b55fd4a68eaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'coarse_label', 'fine_label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the first 1K rows of the TREC dataset\n",
        "trec = load_dataset('trec', split='train[:1000]')\n",
        "trec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKGiLkWpNA1S",
        "outputId": "b5045d50-5e8f-4172-b6c8-70e606cdda2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'How did serfdom develop in and then leave Russia ?',\n",
              " 'coarse_label': 2,\n",
              " 'fine_label': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "trec[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQc5RPosNA1T"
      },
      "source": [
        "We can then pass these questions to Cohere to create embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfAT8ojCNA1T"
      },
      "outputs": [],
      "source": [
        "embeds = co.embed(\n",
        "    texts=trec['text'],\n",
        "    model='small',\n",
        "    truncate='LEFT'\n",
        ").embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojqPN8ZjNA1T"
      },
      "source": [
        "We can check the dimensionality of the returned vectors, for this we will convert it from a list of lists to a Numpy array. We will need to save the embedding dimensionality from this to be used when initializing our Pinecone index later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7NKhUeNA1T",
        "outputId": "5d07110f-757f-42be-d640-2f5828a9cff0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "shape = np.array(embeds).shape\n",
        "shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJoX68NENA1T"
      },
      "source": [
        "Here we can see the `1024` embedding dimensionality produced by Cohere's small model, and the `1000` samples we built embeddings for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enzeBYDONA1U"
      },
      "source": [
        "## Storing the Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5I5jsQwNA1U"
      },
      "source": [
        "Now that we have our embeddings we can move on to indexing them in the Pinecone vector database. Again, this is very simple, we just initialize our connection to Pinecone and then create a new index for storing the embeddings, making sure to specify that we would like to use the cosine similarity metric to align with Cohere's embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwNgMCVgNA1U"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(\n",
        "    PINECONE_KEY,\n",
        "    environment=environment  # find next to API key in console\n",
        ")\n",
        "\n",
        "index_name = 'cohere-pinecone-trec'\n",
        "\n",
        "# if the index does not exist, we create it\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=shape[1],\n",
        "        metric='cosine'\n",
        "    )\n",
        "\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f20oKqIMNA1U"
      },
      "source": [
        "Now we can begin populating the index with our embeddings. Pinecone expects us to provide a list of tuples in the format *(id, vector, metadata)*, where the *metadata* field is an optional extra field where we can store anything we want in a dictionary format. For this example, we will store the original text of the embeddings.\n",
        "\n",
        "While uploading our data, we will batch everything to avoid pushing too much data in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO1U0uvZNA1U",
        "outputId": "a23c45ae-e47a-419b-d80b-0d332309e4be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1024,\n",
              " 'index_fullness': 0.01,\n",
              " 'namespaces': {'': {'vector_count': 1000}},\n",
              " 'total_vector_count': 1000}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "batch_size = 128\n",
        "\n",
        "ids = [str(i) for i in range(shape[0])]\n",
        "# create list of metadata dictionaries\n",
        "meta = [{'text': text} for text in trec['text']]\n",
        "\n",
        "# create list of (id, vector, metadata) tuples to be upserted\n",
        "to_upsert = list(zip(ids, embeds, meta))\n",
        "\n",
        "for i in range(0, shape[0], batch_size):\n",
        "    i_end = min(i+batch_size, shape[0])\n",
        "    index.upsert(vectors=to_upsert[i:i_end])\n",
        "\n",
        "# let's view the index statistics\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49rMcQEeNA1U"
      },
      "source": [
        "Perfect, we can see from `index.describe_index_stats` that we have a *1024-dimensionality* index populated with *1000* embeddings. The `indexFullness` metric tells us how full our index is, at the moment it is empty. Using the default value of one *p1* pod we can fit ~750K embeddings before the `indexFullness` reaches capacity. The [Usage Estimator](www.pinecone.io/pricing) can be used to identify the number of pods required for a given number of *n*-dimensional embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r3G0L9MNA1V"
      },
      "source": [
        "## Semantic Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqQ6-UVHNA1V"
      },
      "source": [
        "Now that we have our indexed vectors we can perform a few search queries. When searching we will first embed our query using Cohere, and then search using the returned vector in Pinecone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEq-2XDMNA1V",
        "outputId": "c0d9ba22-e99d-42d9-9229-e12d07b3587c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1024)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': '887',\n",
              "              'metadata': {'text': 'What events happened January 26 , 1978 ?'},\n",
              "              'score': 0.813806176,\n",
              "              'values': []},\n",
              "             {'id': '367',\n",
              "              'metadata': {'text': 'What Jewish holiday saw the start of the '\n",
              "                                   '1973 Mideast War ?'},\n",
              "              'score': 0.524388194,\n",
              "              'values': []},\n",
              "             {'id': '969',\n",
              "              'metadata': {'text': 'What are some of the significant '\n",
              "                                   'historical events of the 1990s ?'},\n",
              "              'score': 0.513988614,\n",
              "              'values': []},\n",
              "             {'id': '775',\n",
              "              'metadata': {'text': 'What historical event happened in Dogtown '\n",
              "                                   'in 1899 ?'},\n",
              "              'score': 0.490166336,\n",
              "              'values': []},\n",
              "             {'id': '919',\n",
              "              'metadata': {'text': 'What astronomical phenomenon takes place '\n",
              "                                   'in Jan. 1999 ?'},\n",
              "              'score': 0.452435374,\n",
              "              'values': []},\n",
              "             {'id': '906',\n",
              "              'metadata': {'text': 'What year did Germany sign its '\n",
              "                                   'nonaggression pact with the Soviet Union '\n",
              "                                   '?'},\n",
              "              'score': 0.445406258,\n",
              "              'values': []},\n",
              "             {'id': '896',\n",
              "              'metadata': {'text': 'What year did the Vietnam War end ?'},\n",
              "              'score': 0.441116512,\n",
              "              'values': []},\n",
              "             {'id': '425',\n",
              "              'metadata': {'text': 'What year did Hitler die ?'},\n",
              "              'score': 0.421955019,\n",
              "              'values': []},\n",
              "             {'id': '893',\n",
              "              'metadata': {'text': 'When was the San Francisco fire ?'},\n",
              "              'score': 0.396925628,\n",
              "              'values': []},\n",
              "             {'id': '160',\n",
              "              'metadata': {'text': 'What war did the Wanna-Go-Home Riots occur '\n",
              "                                   'after ?'},\n",
              "              'score': 0.390126854,\n",
              "              'values': []}],\n",
              " 'namespace': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# query = \"What caused the 1929 Great Depression?\"\n",
        "\n",
        "query = \"what event occured at 1978\"\n",
        "\n",
        "# create the query embedding\n",
        "xq = co.embed(\n",
        "    texts=[query],\n",
        "    model='small',\n",
        "    truncate='LEFT'\n",
        ").embeddings\n",
        "\n",
        "print(np.array(xq).shape)\n",
        "\n",
        "# query, returning the top 10 most similar results\n",
        "res = index.query(xq, top_k=10, include_metadata=True)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve68DEOUNA1V"
      },
      "source": [
        "The response from Pinecone includes our original text in the `metadata` field, let's print out the `top_k` most similar questions and their respective similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X3jpU3TNA1V",
        "outputId": "cd1923cf-f43a-4054-cb96-cad36366a5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.81: What events happened January 26 , 1978 ?\n",
            "0.52: What Jewish holiday saw the start of the 1973 Mideast War ?\n",
            "0.51: What are some of the significant historical events of the 1990s ?\n",
            "0.49: What historical event happened in Dogtown in 1899 ?\n",
            "0.45: What astronomical phenomenon takes place in Jan. 1999 ?\n",
            "0.45: What year did Germany sign its nonaggression pact with the Soviet Union ?\n",
            "0.44: What year did the Vietnam War end ?\n",
            "0.42: What year did Hitler die ?\n",
            "0.40: When was the San Francisco fire ?\n",
            "0.39: What war did the Wanna-Go-Home Riots occur after ?\n"
          ]
        }
      ],
      "source": [
        "for match in res['matches']:\n",
        "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yKEvtGWNA1V"
      },
      "source": [
        "Looks good, let's make it harder and replace *\"depression\"* with the incorrect term *\"recession\"*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY5NSwiGNA1V",
        "outputId": "99f00263-cd81-4213-f272-3c84037940bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.66: Why did the world enter a global depression in 1929 ?\n",
            "0.61: When was `` the Great Depression '' ?\n",
            "0.43: What crop failure caused the Irish Famine ?\n",
            "0.43: What are some of the significant historical events of the 1990s ?\n",
            "0.37: What were popular songs and types of songs in the 1920s ?\n",
            "0.36: When did the Dow first reach ?\n",
            "0.34: What war did the Wanna-Go-Home Riots occur after ?\n",
            "0.34: What historical event happened in Dogtown in 1899 ?\n",
            "0.33: What is considered the costliest disaster the insurance industry has ever faced ?\n",
            "0.31: What was the education system in the 1960 's ?\n"
          ]
        }
      ],
      "source": [
        "query = \"What was the cause of the major recession in the early 20th century?\"\n",
        "\n",
        "# create the query embedding\n",
        "xq = co.embed(\n",
        "    texts=[query],\n",
        "    model='small',\n",
        "    truncate='LEFT'\n",
        ").embeddings\n",
        "\n",
        "# query, returning the top 10 most similar results\n",
        "res = index.query(xq, top_k=10, include_metadata=True)\n",
        "\n",
        "for match in res['matches']:\n",
        "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6aPDXFTNA1V"
      },
      "source": [
        "And again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQYU6_bkNA1V",
        "outputId": "1487f337-5458-4e07-873b-40b8880d7f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.71: Why did the world enter a global depression in 1929 ?\n",
            "0.62: When was `` the Great Depression '' ?\n",
            "0.40: What crop failure caused the Irish Famine ?\n",
            "0.38: What are some of the significant historical events of the 1990s ?\n",
            "0.38: When did the Dow first reach ?\n",
            "0.35: What were popular songs and types of songs in the 1920s ?\n",
            "0.33: What was the education system in the 1960 's ?\n",
            "0.32: Give a reason for American Indians oftentimes dropping out of school .\n",
            "0.31: What war did the Wanna-Go-Home Riots occur after ?\n",
            "0.30: What historical event happened in Dogtown in 1899 ?\n"
          ]
        }
      ],
      "source": [
        "query = \"Why was there a long-term economic downturn in the early 20th century?\"\n",
        "\n",
        "# create the query embedding\n",
        "xq = co.embed(\n",
        "    texts=[query],\n",
        "    model='small',\n",
        "    truncate='LEFT'\n",
        ").embeddings\n",
        "\n",
        "# query, returning the top 10 most similar results\n",
        "res = index.query(xq, top_k=10, include_metadata=True)\n",
        "\n",
        "for match in res['matches']:\n",
        "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJc2kj9-pGpc"
      },
      "source": [
        "Looks great, our semantic search pipeline is clearly able to identify the meaning between each of our queries and return the most semantically similar questions from the already indexed questions.\n",
        "\n",
        "Once we're done with the index we delete it to save resources:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR-oj6C9NA1W"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rqjo0yd7azVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7 (main, Sep 14 2022, 22:38:23) [Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}